{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+FtWg+6JImoNm/WbDE8mO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepthibasuthkar1608/EcoBuilder/blob/main/Project_Codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lifelines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7snYztb7RX72",
        "outputId": "46c1b151-bab8-4623-9dce-6e29c6828085"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lifelines\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.14.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.7.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=a38bb5871a0dc30a92ed57fbb6988c8332a2852cce2c9524247d1c275ac2e2e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lifelines import CoxPHFitter, WeibullAFTFitter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data and preprocess\n",
        "data = pd.read_csv('/content/Diabetes Classification.csv').replace('-', np.nan)\n",
        "data['Gender'] = data['Gender'].map({'F': 0, 'M': 1})\n",
        "features = ['Age', 'Gender', 'BMI', 'Chol', 'TG', 'HDL', 'LDL', 'Cr', 'BUN']\n",
        "data = data.dropna(subset=['BUN', 'Cr'])  # Note the changes in the list\n",
        "\n",
        "# Example: Mean imputation\n",
        "data[features] = data[features].fillna(data[features].mean())  # Fill NaNs with mean\n",
        "\n",
        "X = StandardScaler().fit_transform(data[features])\n",
        "y = np.random.randint(365, 365*5, len(data))\n",
        "event = data['Diagnosis'].values\n",
        "print(data[features].isnull().sum()) # Check for NaNs\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test, event_train, event_test = train_test_split(X, y, event, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataFrame for lifelines\n",
        "train_df = pd.DataFrame(X_train, columns=features)\n",
        "train_df['duration'] = y_train\n",
        "train_df['event'] = event_train\n",
        "\n",
        "# Cox PH model\n",
        "cph = CoxPHFitter().fit(train_df, 'duration', 'event')\n",
        "# Get predictions (example: survival probability at time t=100 for the first individual)\n",
        "# cox_predictions = cph.predict_survival_function(pd.DataFrame(X_test, columns=features)).loc[100, 0]\n",
        "\n",
        "# AFT model (Weibull)\n",
        "aft = WeibullAFTFitter().fit(train_df, 'duration', 'event')\n",
        "# Get predictions (example: survival probability at time t=100 for the first individual)\n",
        "# aft_predictions = aft.predict_survival_function(pd.DataFrame(X_test, columns=features)).loc[100, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwge5lCWRh3n",
        "outputId": "cf5a328d-52ac-4dfb-a2f6-2533f1cbaf20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age       0\n",
            "Gender    0\n",
            "BMI       0\n",
            "Chol      0\n",
            "TG        0\n",
            "HDL       0\n",
            "LDL       0\n",
            "Cr        0\n",
            "BUN       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sB7rUypRGsb",
        "outputId": "43c5a9e2-e7db-4148-ed0b-6020237203ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age       0\n",
            "Gender    0\n",
            "BMI       0\n",
            "Chol      0\n",
            "TG        0\n",
            "HDL       0\n",
            "LDL       0\n",
            "Cr        0\n",
            "BUN       0\n",
            "dtype: int64\n",
            "Cox prediction: 0.9998426944856829\n",
            "AFT prediction: 0.996432284198911\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lifelines import CoxPHFitter, WeibullAFTFitter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data and preprocess\n",
        "data = pd.read_csv('/content/Diabetes Classification.csv').replace('-', np.nan)\n",
        "data['Gender'] = data['Gender'].map({'F': 0, 'M': 1})\n",
        "features = ['Age', 'Gender', 'BMI', 'Chol', 'TG', 'HDL', 'LDL', 'Cr', 'BUN']\n",
        "data = data.dropna(subset=['BUN', 'Cr'])  # Note the changes in the list\n",
        "\n",
        "# Example: Mean imputation\n",
        "data[features] = data[features].fillna(data[features].mean())  # Fill NaNs with mean\n",
        "\n",
        "X = StandardScaler().fit_transform(data[features])\n",
        "y = np.random.randint(365, 365*5, len(data))\n",
        "event = data['Diagnosis'].values\n",
        "print(data[features].isnull().sum()) # Check for NaNs\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test, event_train, event_test = train_test_split(X, y, event, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataFrame for lifelines\n",
        "train_df = pd.DataFrame(X_train, columns=features)\n",
        "train_df['duration'] = y_train\n",
        "train_df['event'] = event_train\n",
        "\n",
        "# Cox PH model\n",
        "cph = CoxPHFitter().fit(train_df, 'duration', 'event')\n",
        "# Get predictions (example: survival probability at time t=100 for the first individual)\n",
        "cox_predictions = cph.predict_survival_function(pd.DataFrame(X_test, columns=features))\n",
        "aft_predictions = aft.predict_survival_function(pd.DataFrame(X_test, columns=features))\n",
        "# for example, patient at index 0, and time = 100\n",
        "cox_prob = cox_predictions.iloc[0, cox_predictions.columns.get_loc(100)]\n",
        "aft_prob = aft_predictions.iloc[0, aft_predictions.columns.get_loc(100)]\n",
        "\n",
        "print(\"Cox prediction:\", cox_prob)\n",
        "print(\"AFT prediction:\", aft_prob)"
      ]
    }
  ]
}